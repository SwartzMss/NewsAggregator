## 新闻去重方案概览

本方案希望在文章入库前识别「同一新闻在不同源重复发布」的情况，避免列表出现重复内容，同时保留多源引用信息，方便后续展示和分析。整体流程分为多层过滤，只有在判定不确定时才调用大模型。

### 目标
- 阻止重复新闻进入 `news.articles` 主表，或将它们与已有文章关联。
- 尽量保留其他来源的信息（发布时间、源站、原始 URL）。
- 控制成本与延迟，对高并发抓取保持可扩展性。

### 总体流程
1. **预处理：URL 与标题归一化**  
   - 去掉追踪参数（`utm_*` 等）、统一协议/域名、修剪空格和标点。  
   - 标题统一大小写、移除噪声字符（如站点前缀）。

2. **快速规则判定**  
   - 直接命中 `(feed_id, normalized_url)` 唯一约束 → 视为重复。  
   - URL 完全相同 → 视为重复。  
   - 发布时间差距超出阈值（如 >48 小时） → 视为不同。  
   - 标题完全一致且发布时间很接近 → 视为重复。

3. **轻量相似度计算**  
   - **规则/哈希**：对标题做归一化后计算 Jaccard、SimHash 等，快速拦截明显重复。  
   - **向量近邻**：使用嵌入模型生成向量并在 Qdrant 等向量库里检索 Top-K 候选。Qdrant 可本地部署（Docker/二进制均可），Rust 端通过官方 SDK 写入/查询，并可附加时间窗口过滤。  
   - 设定双阈值：高于上限 → 判重复；低于下限 → 判不同；介于两者 → 进入下一层。

4. **大模型判定（DeepSeek 等）**  
   - 对“灰区”候选，将标题、来源、发布时间、摘要等信息组装成 prompt，明确让模型回答“是否同一新闻”和理由。  
   - 模型只返回“是/否 + 简短说明”，便于机器解析。
   - 已在 `backend/src/util/deepseek.rs` 实现了调用 DeepSeek Chat Completion 的客户端（`DeepseekClient::judge_similarity`），尚未集成到业务流；接入时需配置 `DEEPSEEK_API_KEY` 或在 `config.yaml` 的 `ai.deepseek` 节点。
   - 对结果做缓存：同一组合下次直接复用。

5. **数据落库策略**
   - 新建 `news.article_sources` 表记录文章与来源的映射，可包含 `article_id`、`feed_id`、`source_name`、`source_url`、`published_at`、`inserted_at`，并对 `(article_id, source_url)` 建唯一约束，允许同一篇主新闻关联多个源。
   - `news.articles` 保持主新闻记录，可考虑新增 `canonical_article_id`（默认等于自身），用于在需要保留重复记录时指向主记录。
   - 判定为全新新闻：插入 `news.articles`，随后写入主来源到 `news.article_sources`。
- 判定为重复：不再插入 `news.articles`，只向 `news.article_sources` 追加一条引用，让 `article_id` 指向主新闻，同时保存来源名称、链接、发布时间以及判定元数据。
- 可选：在 `news.article_sources` 或独立表中记录大模型判定结果（决策、置信度、prompt hash 等），便于审计和调优。

6. **观察与回溯**
   - 监控判定结果（重复/非重复的比例、模型调用次数、平均延迟）。
   - 对模型输出进行抽样人工复核，必要时调整阈值或 prompt。
   - 提供批处理脚本，对历史数据进行去重迁移。

### 精选排序的后续优化思路
- 维持当前点击量降序的主排序逻辑，同时只考虑最近 24 小时的文章。
- 引入来源权重：当点击量相同或接近时，可按照 `source_count`（`news.article_sources` 中关联的来源条数）进行次排序，让被多家源报道的新闻优先展示。
- 具体实现待数据结构和去重链路落地后再更新，包括如何在查询中统计来源数量、是否需要缓存或物化视图等。

### 实施建议
- **第一阶段**：先上线 URL 归一化 + `(feed_id, url)` 唯一约束 + 发布时间窗口，初步减少重复。
- **第二阶段**：实现标题归一化 + Jaccard/SimHash 等轻量规则过滤，对高优先级重复直接拦截。
- **第三阶段**：部署 Qdrant（或另一向量库），设定嵌入模型，完成向量写入/Top-K 检索，提供候选集合。
  - 当前代码中已提供 `backend/src/util/qdrant.rs` 的 `QdrantManager` 封装，可复用配置 (`config.ai.qdrant`) 建立集合、写入向量并检索近邻。
- **第四阶段**：接入 DeepSeek 客户端，对灰区候选进行判定（目前 `backend/src/util/deepseek.rs` 已具备调用能力，待集成）。
- **第五阶段**：扩展数据库结构（新增 `news.article_sources`、`canonical_article_id` 等）并调整入库流程、API 返回值。
- **展示层**：若启用引用表，在 API 返回时附带 `sources` 列表，展示“该新闻还来自哪些源站/时间”。  
- **后续优化**：记录模型答案，结合反馈不断调整 prompt 和阈值，必要时训练自定义分类器替换部分模型调用。

通过这种多层过滤机制，可以在成本可控的前提下显著降低跨源重复新闻的占比，同时保留业务上有价值的多源信息。
